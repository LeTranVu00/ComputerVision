import torch
import cv2
import numpy as np
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
import os
import glob

# ==========================================
# 1. C·∫§U H√åNH
# ==========================================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_NAME = 'best_unet_ham10000_v2.pth' # T√™n file model c·ªßa b·∫°n
MODEL_PATH = os.path.join(CURRENT_DIR, MODEL_NAME)

INPUT_FOLDER = os.path.join(CURRENT_DIR, 'input_images')
OUTPUT_FOLDER = os.path.join(CURRENT_DIR, 'output_results')

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
IMG_SIZE = 256

# ==========================================
# 2. C√ÅC H√ÄM X·ª¨ L√ù
# ==========================================
# H√†m n·∫°p model ƒë√£ hu·∫•n luy·ªán
def load_model(path):
    print(f"‚è≥ ƒêang n·∫°p model t·ª´: {path}")
    model = smp.Unet(encoder_name="resnet34", encoder_weights=None, in_channels=3, classes=1)
    if not os.path.exists(path):
        print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file model t·∫°i {path}")
        return None
    model.load_state_dict(torch.load(path, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    return model

# H√†m d·ª± ƒëo√°n mask cho m·ªôt ·∫£nh
def predict_image(model, img_path):
    image = cv2.imread(img_path)
    if image is None: return None, None
    
    original_img = image.copy()
    original_h, original_w = image.shape[:2]
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    transform = A.Compose([
        A.Resize(IMG_SIZE, IMG_SIZE),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2(),
    ])
    augmented = transform(image=image_rgb)
    input_tensor = augmented['image'].unsqueeze(0).to(DEVICE)
    
    with torch.no_grad():
        output = model(input_tensor)
        prob_mask = torch.sigmoid(output)
        pred_mask = (prob_mask > 0.5).float().squeeze().cpu().numpy()
    
    pred_mask_resized = cv2.resize(pred_mask, (original_w, original_h), interpolation=cv2.INTER_NEAREST)
    return original_img, pred_mask_resized

# H√†m t·∫°o ·∫£nh ch·ªìng l·ªõp (·∫£nh k·∫øt qu·∫£)
def create_overlay(original_img, mask):
    # T·∫°o overlay ƒë·ªÉ l∆∞u v√† hi·ªÉn th·ªã
    colored_mask = np.zeros_like(original_img)
    colored_mask[:, :, 1] = 255 # M√†u xanh l√°
    
    overlay = original_img.copy()
    overlay[mask > 0] = cv2.addWeighted(original_img[mask > 0], 0.6, colored_mask[mask > 0], 0.4, 0)
    
    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(overlay, contours, -1, (0, 0, 255), 2)
    return overlay

# ==========================================
# 3. CH∆Ø∆†NG TR√åNH CH√çNH
# ==========================================
if __name__ == "__main__":
    if not os.path.exists(INPUT_FOLDER):
        os.makedirs(INPUT_FOLDER)
        print(f"‚ö†Ô∏è ƒê√£ t·∫°o th∆∞ m·ª•c '{INPUT_FOLDER}'. H√£y b·ªè ·∫£nh v√†o ƒë√≥ r·ªìi ch·∫°y l·∫°i.")
        exit()
        
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    
    # L·∫•y danh s√°ch ·∫£nh
    image_paths = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        image_paths.extend(glob.glob(os.path.join(INPUT_FOLDER, ext)))
    
    if not image_paths:
        print("‚ùå Kh√¥ng th·∫•y ·∫£nh n√†o!")
        exit()

    model = load_model(MODEL_PATH)
    
    if model is not None:
        print(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(image_paths)} ·∫£nh...")
        print("üí° H∆Ø·ªöNG D·∫™N: Nh·∫•n ph√≠m b·∫•t k·ª≥ ƒë·ªÉ qua ·∫£nh ti·∫øp theo. Nh·∫•n 'q' ƒë·ªÉ tho√°t.")

        for i, img_path in enumerate(image_paths):
            filename = os.path.basename(img_path)
            print(f"[{i+1}/{len(image_paths)}] ƒêang x·ª≠ l√Ω: {filename}")
            
            # 1. D·ª± ƒëo√°n
            img, mask = predict_image(model, img_path)
            
            if img is not None:
                # 2. T·∫°o k·∫øt qu·∫£ ch·ªìng l·ªõp
                overlay = create_overlay(img, mask)
                
                # 3. L∆∞u xu·ªëng ·ªï c·ª©ng
                save_path = os.path.join(OUTPUT_FOLDER, f"result_{filename}")
                cv2.imwrite(save_path, overlay)
            
                # Resize v·ªÅ c√πng k√≠ch th∆∞·ªõc nh·ªè (v√≠ d·ª• 300x300) ƒë·ªÉ gh√©p cho ƒë·∫πp
                view_size = (300, 300)
                v_orig = cv2.resize(img, view_size)
                
                # Mask c·∫ßn chuy·ªÉn t·ª´ x√°m sang m√†u ƒë·ªÉ gh√©p
                v_mask = cv2.resize(mask, view_size)
                v_mask = (v_mask * 255).astype(np.uint8) # Chuy·ªÉn 0-1 th√†nh 0-255
                v_mask = cv2.cvtColor(v_mask, cv2.COLOR_GRAY2BGR) 
                
                v_over = cv2.resize(overlay, view_size)
                
                # Gh√©p 3 ·∫£nh n·∫±m ngang (Horizontal Stack)
                combined_view = np.hstack([v_orig, v_mask, v_over])
                
                # Th√™m ch·ªØ ch√∫ th√≠ch
                cv2.putText(combined_view, "Original", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                cv2.putText(combined_view, "AI Mask", (310, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                cv2.putText(combined_view, "Result", (610, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

                # 5. Hi·ªán c·ª≠a s·ªï
                cv2.imshow("Skin Lesion Analysis (Nhan phim bat ky de tiep tuc, 'q' de thoat)", combined_view)
                
               
                key = cv2.waitKey(0) 
                if key == ord('q'): 
                    print("üõë ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh.")
                    break

        cv2.destroyAllWindows()
        print("\n‚úÖ Ho√†n t·∫•t!")